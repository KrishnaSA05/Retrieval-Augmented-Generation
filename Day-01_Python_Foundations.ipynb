{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef63ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Structures\n",
    "#Lists - Ordered collections of items\n",
    "\n",
    "documents = [\"doc1.txt\", \"doc2.txt\", \"doc3.txt\"]\n",
    "chunks = []  # Empty list to store text chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dictionaries - Key-value pairs (perfect for storing metadata)\n",
    "\n",
    "document_info = {\n",
    "    \"filename\": \"article.pdf\",\n",
    "    \"page_count\": 10,\n",
    "    \"author\": \"John Doe\",\n",
    "    \"chunks\": []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5151f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tuples - Immutable ordered collections\n",
    "\n",
    "api_config = (\"https://api.openai.com\", \"v1\", \"gpt-4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18ea40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File Handling\n",
    "#Reading and writing files is essential for RAG:\n",
    "#File → Read → Process → Store\n",
    "\n",
    "#Reading text files:\n",
    "with open(\"document.txt\",\"r\", encoding=\"utf-8\") as file:\n",
    "    content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e778c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Writing to files:\n",
    "with open(\"document.txt\" , \"w\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"Processed content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90797fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#append in data to existing file\n",
    "with open(\"document.txt\" , \"a\", encoding=\"utf-8\") as file:\n",
    "    file.write(\"\\nAdditional content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2adff26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions and Classes\n",
    "#Functions - Reusable blocks of code\n",
    "\n",
    "def chunk_text(text, chunk_size):\n",
    "    \"\"\"Split text into chunks of specified size\"\"\"\n",
    "    chunks = []\n",
    "    for i in range(0, len(text), chunk_size):\n",
    "        chunks.append(text[i:i+chunk_size]) #text[start_index : end_index] --> text[0 : 4] --> text[4 : 8] --> text[8 : 12]....\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91346f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello, I a', 'm learning', ' how to sp', 'lit text i', 'nto chunks', '.']\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello, I am learning how to split text into chunks.\"\n",
    "chunks = chunk_text(text, chunk_size=10)\n",
    "print(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525fc718",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classes - Organizing related functionality\n",
    "class DocumnentProcessor:\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.content = \"\"\n",
    "\n",
    "    def load(self):\n",
    "        with open(self.filemame, \"r\", encoding= \"utf-8\") as file:\n",
    "            self.content = file.read()\n",
    "\n",
    "    def get_word_count(self):\n",
    "        return len(self.content.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92a0dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working with APIs\n",
    "#RAG systems interact with APIs (like OpenAI):\n",
    "\n",
    "#Your Code → HTTP Request → API → Response → Your Code\n",
    "\n",
    "#Basic API interaction pattern:\n",
    "import requests\n",
    "\n",
    "def call_api(url, data):\n",
    "    response = requests.post(url, json=data)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a503c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List Comprehensions and Generators\n",
    "#List comprehensions - Concise way to create lists\n",
    "\n",
    "# Traditional way\n",
    "squares = []\n",
    "for x in range(10):\n",
    "    squares.append(x**2)\n",
    "\n",
    "# List comprehension\n",
    "squares = [x**2 for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "817438ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generators - Memory-efficient iteration\n",
    "def chunk_generator(text, chunk_size):\n",
    "    for i in range(0, len(text), chunk_size):\n",
    "        yield text[i:i+chunk_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67074656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, I a\n",
      "m learning\n",
      " how to sp\n",
      "lit text i\n",
      "nto chunks\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "#Using the generator \n",
    "for chunk in chunk_generator(text, 10):\n",
    "    print(chunk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "28b07058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instructor Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebf0905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Reading and Processing a Text File\n",
    "def read_and_process_file(filename):\n",
    "    #Read a file and return processed content\n",
    "    try:\n",
    "        with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "            content = file.read()\n",
    "\n",
    "            #basic processing:\n",
    "            lines = content.split(\"\\n\")\n",
    "            word_count = len(content.split())\n",
    "\n",
    "            return{\n",
    "                  \"content\": content,\n",
    "                  \"lines\": len(lines),\n",
    "                  \"words\": word_count\n",
    "            }\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Filename {filename} not found.\")\n",
    "        return None\n",
    "    \n",
    "# Usage\n",
    "result = read_and_process_file(\"sample.txt\")\n",
    "if result:\n",
    "    print(f\"Lines: {result['lines']}, Words: {result['words']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175f5817",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example 2: Text Chunking Function\n",
    "def chunk_text(text, chunk_size=200, overlap=50):\n",
    "    \"\"\"\n",
    "    Split text into overlapping chunks\n",
    "\n",
    "    Args:\n",
    "        text: Input text to chunk\n",
    "        chunk_size: Size of each chunk\n",
    "        overlap: Number of characters to overlap between chunks\n",
    "    \"\"\"\n",
    "    chunks = []\n",
    "    start = 0\n",
    "\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunk = text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start = end - overlap  # Overlap for context\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Usage\n",
    "long_text = \"This is a very long document...\" * 100\n",
    "chunks = chunk_text(long_text, chunk_size=200, overlap=50)\n",
    "print(f\"Created {len(chunks)} chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98e831db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'filename': 'article.txt', 'words': 7, 'chunks': 2}\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Working with Dictionaries for Document Metadata\n",
    "\n",
    "class Document:\n",
    "    def __init__(self, filename, content):\n",
    "        self.filename = filename\n",
    "        self.content = content\n",
    "        self.metadata = {\n",
    "            \"word_count\": len(content.split()),\n",
    "            \"char_count\": len(content),\n",
    "            \"chunks\": []\n",
    "        }\n",
    "\n",
    "    def add_chunk(self, chunk_text, chunk_id):\n",
    "        chunk_data = {\n",
    "            \"id\": chunk_id,\n",
    "            \"text\": chunk_text,\n",
    "            \"length\": len(chunk_text)\n",
    "        }\n",
    "        self.metadata[\"chunks\"].append(chunk_data)\n",
    "\n",
    "    def get_summary(self):\n",
    "        return {\n",
    "            \"filename\": self.filename,\n",
    "            \"words\": self.metadata[\"word_count\"],\n",
    "            \"chunks\": len(self.metadata[\"chunks\"])\n",
    "        }\n",
    "\n",
    "# Usage\n",
    "doc = Document(\"article.txt\", \"This is the content of the article...\")\n",
    "doc.add_chunk(\"First chunk\", 1)\n",
    "doc.add_chunk(\"Second chunk\", 2)\n",
    "print(doc.get_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74333242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Simple API Request Pattern\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def make_api_request(url, payload, headers=None):\n",
    "    \"\"\"Make a POST request to an API\"\"\"\n",
    "    default_headers = {\"Content-Type\": \"application/json\"}\n",
    "    if headers:\n",
    "        default_headers.update(headers)\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=payload, headers=default_headers)\n",
    "        response.raise_for_status()  # Raises exception for bad status codes\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"API request failed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Usage pattern (you'll use this with OpenAI API later)\n",
    "# payload = {\"prompt\": \"Hello, world!\"}\n",
    "# result = make_api_request(\"https://api.example.com/endpoint\", payload)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
